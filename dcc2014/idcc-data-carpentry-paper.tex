%\documentclass[practice]{ijdc-v9}
\documentclass[15]{idcc}


\title[Data Carpentry]{Data Carpentry: \\workshops to increase data literacy for researchers}
\author{Tracy~K.~Teal}
\affil{Michigan State University, East Lansing, MI, USA}
\author{Karen~A.~Cranston}
\affil{National Evolutionary Synthesis Center (NESCent), Durham, NC, USA}
\author{Hilmar~Lapp}
\affil{National Evolutionary Synthesis Center (NESCent), Durham, NC, USA}
\author{Ethan~White}
\affil{Utah State University, Logan, UT, USA}
\author{Greg Wilson}
\affil{Software Carpentry Foundation, Toronto, Canada}
\author{Karthik Ram}
\affil{Section of Evolution and Ecology, University of California, Davis, CA, USA}
\author{Aleksandra Pawlik}
\affil{University of Manchester, United Kingdom}
\correspondence{Aleksandra Pawlik, Room 1.17 Kilburn Building, Oxford Road, University of Manchester, M13 9PL, Manchester, United Kingdom. Email: \email{aleksandra.pawlik@manchester.ac.uk} }


\begin{document}

\maketitle



\section{Abstract}
In many domains the rapid generation of large amounts of data is fundamentally changing how research is done. The deluge of data presents great opportunities, but also many challenges in managing, analyzing and sharing data. Good training resources for researchers looking to develop skills that will enable them to be more effective and productive researchers are scarce. To address this need we have developed an introductory two-day intensive workshop, Data Carpentry, designed to teach basic concepts, skills, and tools for working more effectively and reproducibly with data.\\

Software Carpentry, two-day hands-on bootcamp style workshops teaching best practices in software development, have demonstrated the success of short workshops to teach foundational research skills. This model has been adapted for Data Carpentry with the objective of teaching skills to researchers to enable them to retrieve, view, manipulate, analyze and store their and other's data in an open and reproducible way, through the data lifecycle and be able to extract knowledge from data.\\

\section{Introduction}

With the increasing ability to digitize text and collections, automate data collection, conduct
large scale surveys and generate vast genomic, astronomical or other type of data there is
the great potential to conduct data-driven research and address questions in all fields that
were not previously possible. However, despite this promise, analysis of these datasets
presents a major challenge. Many researchers lack the computational and statistical training
required for appropriate data analysis or a working vocabulary to communicate their analysis
needs to computer scientists or statisticians. With
few exceptions, they are unfamiliar with best practices and tools in the data lifecycle: most or all of what they know about data
management, analysis, and sharing (including the development and use of analysis software) has been learned piecemeal, or not learned
at all.

This is especially concerning because it limits the ability of researchers to make progress on these important questions
 or resulted in inaccurate or incomplete analyses that can lead to erroneous conclusions. It also
leads to the generation of data that ultimately cannot be used to answer research questions, wasting
or underutilizing available resources.

Most researchers want to address this issue and improve the way they manage and analyze data.
A survey of researchers in the National Science Foundation's BIO Centers revealed not only gaps in knowledge in data management and analysis, but also that researchers are frustrated with
their current data workflows and know their research capacity is being limited by this lack of knowledge. In a Bioinformatics Resource Australia EMBL 2013 Community Survey Report the most emphatic outcome was the overwhelming demand for training\footnote{\url{http://braembl.org.au/news/braembl-community-survey-report-2013}}. More than 60\% of researchers surveyed said that their greatest need was additional training, compared to a meagre 5\% who need access to additional compute power.  While this survey is focused on biology and bioinformatics, the sentiment is shared by researchers in many domains and regions and has been clearly identified by ELIXIR-UK as well. Fundamentally this lack of skills and of confidence is limiting research progress.

However, good training resources for researchers looking to develop these skills are scarce and it is difficult to determine where to start. Training in data and computing skills is still
largely absent from undergraduate and graduate programs for biomedical researchers. Self-guided study such as online lessons,
MOOCs and books are available, but there is a significant challenge in being able to discover relevant and high-quality
 materials and for already busy researchers to commit their time and focus to these learning activities. The completion rate for MOOCs in particular is less than 10\% \url{http://www.katyjordan.com/MOOCproject.html}. Also training resources are often available in areas outside a resarcher's domain, so they have the added challenge of figuring out how to apply learned tools or approaches in the context of their research. Instead, most researchers
learn what they know about programming and data management on their own or the information is passed down within a lab,
and as a result are unfamiliar with the equivalent of good lab practices for data science.  The hidden costs this creates are significant:
researchers spent weeks or months doing things that could be done in hours or days, do not know how trustworthy their results are, and
are often unable to reproduce their own work, much less that of their colleagues.


\section{The workshop model to meet training needs}

There are many challenges in providing effective training in data skills to researchers. One particular challenge is
the substantial variation in the training occurring at institutions. There are many reasons for this. The curriculum
is already full and there is not room to add specific courses or even lectures incorporating these topics. There are
not researchers at a given institution who are able to teach these courses, either through a lack of knowledge
or because of commitments to other activities. Additionally researchers are time-challenged. Existing commitments to research, grants and service often leave little time to develop new skills. Finally
there is not currently a good model for community lesson development, so materials are often developed independently at
each institution or department and there is not the opportunity for community engagement on what would be best taught or
refinement as the lessons are taught multiple times.
Ideally training would
be high quality with materials vetted by practiced instruction, consistent across universities and locations, be able
to be deployed at multiple and disparate locations, allow researchers to interact with the materials and the
instructors and provide a relatively easy entry in to learning new topics.

A hands-on workshop model with community developed lessons is one that addresses these needs. A set of materials can be developed by the community that can share perspectives on best practices and taught broadly. This not only develops a more effective lesson, but
because the same lessons are being taught multiple times there are opportunities for feedback and refinement of the lessons to deliver a higher quality product. The short, focused time of workshops gives researchers committed time to work on developing these skill
sets. The hands on nature gives researchers the chance to develop their computational skills in the course of the workshop, so they
leave with practical examples and hands on experience. Finally workshops can be taught be instructors from outside a given institution, so the institution does not have to rely on local knowledge or availability of instructors.

Software Carpentry has been a leader in this approach to teaching best practices in software development to researchers. It was created in 1998 as two-day
intensive hands-on workshops to teach software practices fundamental to repeatability and accountability in scientific software
development as well as strategies to be more effective and productive - version control, programming, software testing and the command
line - enabling researchers to develop scripts or software that can reduce the time that things can be done from days and weeks to hours
or days. All lessons are developed
collaboratively with the community, and as with open source software, anyone can propose an improvement to its lessons (which are all
freely available under a Creative Commons license).  Those proposals are reviewed, improved, and finally merged into the core so that
everyone can benefit from better explanations, examples, and exercises. All workshops are taught by volunteer instructors, more than 80
of which have been trained in the past year. Since 2010 alone, Software Carpenty has grown into a volunteer organization through which more than 160 instructors have
taught two-day workshops for over 7000 people in 15 countries.

Workshops do scale more effectively than courses, but the in person aspect of workshops and requiring that there are instructors
 for each workshop does limit its scaling. The demand for Software Carpentry workshops seems to be limitless:  workshops
fill within hours of being announced and more universities are requesting workshops than there are instructors available.

\section{Data Carpentry workshops to train researchers in data skills}

Data Carpentry also uses this workshop model and was developed as a sister organization to Software Carpentry. Where Software
Carpentry was developed to train researchers who were already programming better software development practices, Data Carpentry is
being developed to meet the needs of the everyday researcher who has data, big or small,
that they need to analyze.

We have all experienced in our own work and
in our interactions with colleagues how the inability to conduct an analysis or a lack of awareness of available
methods limits research progress and leaves researchers feeling frustrated and disatisfied with their current data processing workflow. This
sentiment was echoed by a survey of the researchers at the NSF BIO Centers, NSF funded centers focused on biological research, and
was the original set of researchers we set out to target with training.

Therefore our initial objectives was to develop a training program that 1. assumes little to no
prior computational experience, 2. has domain specific content to improve learning and demonstrate
the direct application of the skills being taught to leaners' research and 3. to engage the community in the
development and deployment of this training to improve training quality and scalability.

Given the effectiveness of the workshop model and the proven success of Software Carpentry, we developed
Data Carpentry as two-day workshops to meet these data training needs and focus on standard steps in the data workflow -
organizing, managing and analyzing data
in a more efficient and reproducible way. Additionally, because people learn best when new skills are building on
an existing framework, Data Carpentry workshops are designed to be domain specific so researchers can learn more
quickly and effectively and see more
immediately how to implement these skills and approaches in their own work. Also the workshops follow a narrative, using one
domain relevant dataset throughout the workshop, and teaching the tools in the framework of addressing questions from
that dataset.

To attain these objectives in workshops, we identified the following guidelines for the initial Data Carpentry core content:

\begin{itemize}
\item Workshops are domain specific. Each field has its own data types, analysis packages and standard problems to address.
Being able to teach people in their domain let\'s them both more immediately understand the questions and approaches, and then
be able to apply it to their own work. Using examples that are 'real world' to a given domain is fundamentally motivating for
the skills that are being taught.

\item Workshops are a narrative that show the data lifecycle for a given dataset or problem. All components of the data lifecycle
are fundamental in the quality of the final analysis. Emphasizing all the components from setting up data tables, to viewing,
manipulating, analyzing, visualizing and sharing data is crucial for accurate outcomes and reproducible research. Also, this
lifecycle again models a users' workflow, allowing learners to put the process in to action with their own data sets.

\item Workshops are designed for people with no prior computational experience. Learners can walk in with any level of background,
but these workshops assume no prior knowledge. In this way learners should not self-select whether or not they should attend, and
there is clear expectation for the pace of instruction. We also can meet researchers where they are and build on existing practices
and knowledge.

\item These workshops can be focused on any research domain. Social scientists, digital humanists, biologists, librarians,
and museum collections are all facing the same challenges with the digital data deluge. The same principles in the data lifecycle
can be applied in any domain of research and materials adapted to meet the specific needs of that domain.

\section{Data Carpentry progress and future plans}

As our initial workshops focused on researchers in the NSF BIO Centers the first core workshop was developed with
biological/ecological data - a survey of small mammals in a desert ecosystem. Using this dataset the workshops teach
\begin{itemize}
\item How to organize data in spreadsheet programs (such as Excel), use spreadsheets more effectively and the limitations of such programs.
\item Getting data out of spreadsheets and into more powerful tools --- using R or Python.
\item Using databases, including managing and querying data in SQL.
\item Workflows and automating repetitive tasks, in particular using the command line shell and shell scripts.
\end{itemize}

These workshops have now been taught eight times since May, 2014, with many more scheduled for 2015. We have an
  upocoming hackathon event to develop domain specific lessons for genomics and more organically integrate assessment
  into the workshops so that we can evaluate if learning objectives are being met. We have had broad interest in developing lessons
  in the social sciences, geosciences and neurosciences and are working with members of those communities to establish lessons in those
  domains. Additionally there has been interest in these workshops from librarians who are helping researcher manage their data lifecyles
 or are conducting their own analyses with digitized collections.

 While our initial focus is on a core product for introductory workshops, we are planning to develop or incorporate more advanced topics
 such as Natural Lanaguage Processing, more advanced statistical topics, using cloud resources and using APIs for data access and sharing. In these topics and all workshop materials there will be a continued emphasis on conducting data and computation-heavy research more reproducibly and openly.


 We are also developing strategies to work with communities to develop content, respond to user input and solicit lesson contributions and recruit instructors to ensure a diverse, representative pool of contributors. Importantly Data Carpenty has also established a Code of Conduct for
 for both its workshops and participation in its community, and we are committed to providing safe, friendly environments to learn scientific computing.




\section{Assessment}
The need for assesment of the Data Carpentry activities is essential. Our approach to designing and using assesement is influenced by
the experiences of Software Carpentry. The assessment methods used by Software Carpentry have been evolving almost since the workshops became 
increasingly popular. As much as possible, Software Carpentry tried to get advice on assesment from those experiences in education assesment or 
in methodology of surveying different cohorts over time. Data Carpentry tries to follow that approach. \\

It is also worth noting that we use two types of assesment: formal and informal. The formal assesment is conducted using well established 
methodologies such as questionnaire and (in the future) interviews. The formal assesment is thus well documented and allows for comparison
between cohorts of learners and workshops. The questionnaires are fully digitalised which allows for quick and flexible manipulation of the
collected data (it would be rather embarrassing if Data Carpentry struggled with analysing their own datasets!). The informal assesment is 
based on the discussions within the community. Whilst these discussions commonly happen via emails or shared online documents, the information
is not methodologically collected and thus may typically serve as a supporting evidence, especially in any formal documents, such as grant
proposals.\\

The assesment serves two purposes: 
\begin{enumerate}
\item provides us with the feeback from the learners which then allows us improve Data Carpentry in many aspects, such as the mode of
delivery of the workshops, the materials, the dissemination and outreach, and so on.
\item gives us evidence of the effectiveness and impact that Data Carpentry makes within various research areas and communities.
\end{enumerate}

Whenever possible, we try to combine the assesment for both purposes. That is, we try to design our surveys so that their outcomes provide
information and evidence serving both of the above goals. This means that the we do not overload the participants with too many surveys
or other forms of assesment. However, on the other hand assessment planning requires careful approach. Here is how we do it.


\subsection{Assessment to help improve Data Carpentry}
For the formal assessment we use pre- and post-workshop questionnaires. The questionnaires are created using Qualtrics platform\footnote{http://www.qualtrics.com/}
which provides professional tools for running surveys. Qualtrics is used by a number of universities and research institutions in the United States. 
Thanks to the collaboration with iDigBio we were able to run host and run our surveys via this platform. Thanks to help from one of the iDigBio
assesment experts we were able to adapt the original Software Carpentry questionnaire for our own needs. \\

The pre-workshop questionnaire focuses on capturing the information about the relevant computational skills which the participants may already
have before coming to the workshop. By ``relevant'' we mean skills directly corresponding with the modules which we teach at the workshops. The 
participants are asked about their experience with programming languages and tools to manage and analyse data, as well as their everyday practices
in working with data (such as data sharing, licensing and so on). The questionnaire also includes 
a set of questions, or rather short specific tasks for manipulating data, and the participants need to rank their ability to complete these. We also 
ask the participants about their expectations towards the training.  The pre-workshop questionnaire also collects the standard information about
 the participants, such as their name, email, gender, research career level, research area and home institution.\\

Since Data Carpentry is still at its early phase and the number of workshops run so far is not large, the informal feedback comes from direct interactions with the participants. 
The hands-on interactive nature of the workshops allows
the instructors to closely observe the issues that the participants struggle most as well as note which bits of the training the students
found particularily useful. 


\subsection{Assesment for evidence of the impact made by Data Carpentry}



\section{Building a community of instructors}

Running an effective workshop means having instructors trained in how to teach, particularly in a workshop format. Software Carpentry has developed an effective train-the-trainers program based on pedagogy and experience. Data Carpentry instructors will also be trained in this way with Data Carpentry specific modules developed.



\section{Conclusion}


Four Data Carpentry workshops in biology have now been taught with positive response and survey assessment results demonstrating that learning objectives are being met. The research community has been enthusiastic about hosting, teaching or taking these workshops as well as been engaged in the development of materials in other domains and in expanding topics. Work is already progressing on materials for genomics, neuroscience, social science and geoscience and is expanding to include lessons on data visualization and introductory statistics.

Data Carpentry workshops won't be able to teach researchers all the skills they need in two days, but we've shown that they are a way to get the process started and that they can lower the activation energy required for researchers to be able to do more and more effective work with their data and enable research progress.


\end{document}.
